{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MMIDAS - a cpoupled mixutre VAE model\n",
    "This notebook guides you through the process of training a mixture variational autoencoder (VAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmidas.cpl_mixvae import cpl_mixVAE\n",
    "from mmidas.utils.tools import get_paths\n",
    "from mmidas.utils.dataloader import load_data, get_loaders\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 120 # upper bound of number of categories (clusters)\n",
    "state_dim = 2 # continuous (state) variable dimensionality \n",
    "n_arm = 2 # number of arms\n",
    "latent_dim = 10 # latent dimensionality of the model\n",
    "batch_size = 5000 # mini-batch size for training\n",
    "n_epoch = 10 # number of epochs for training\n",
    "n_epoch_p = 5 # number of epochs for pruning\n",
    "min_con = 0.9 # minimum consensus among arms\n",
    "max_prun_it = 2 # maximum number of pruning iterations\n",
    "batch_size = 5000 # mini-batch size for training\n",
    "lr = 1e-3 # learning rate for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the prepared data (as described in ```1_DataPrep.ipynb```) and create training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yeganeh.marghi/github/MMIDAS/pyproject.toml\n",
      "Getting files directories belong to smartseq_files...\n"
     ]
    }
   ],
   "source": [
    "toml_file = 'pyproject.toml'\n",
    "sub_file = 'smartseq_files'\n",
    "config = get_paths(toml_file=toml_file, sub_file=sub_file)\n",
    "data_path = config['paths']['main_dir'] / config['paths']['data_path']\n",
    "data_file = data_path / config[sub_file]['anndata_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is loaded!\n",
      " --------- Data Summary --------- \n",
      "num cell types: 115, num cells: 22365, num genes:5032\n"
     ]
    }
   ],
   "source": [
    "data = load_data(datafile=data_file)\n",
    "trainloader, testloader, _, _, _= get_loaders(dataset=data['log1p'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a designated folder to store training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_run = 1\n",
    "augmentation = False\n",
    "folder_name = f'run_{n_run}_K_{n_categories}_Sdim_{state_dim}_aug_{augmentation}_lr_{lr}_n_arm_{n_arm}_nbatch_{batch_size}' + \\\n",
    "            f'_nepoch_{n_epoch}_nepochP_{n_epoch_p}'\n",
    "saving_folder = config['paths']['main_dir'] / config['paths']['saving_path']\n",
    "saving_folder = saving_folder / folder_name\n",
    "os.makedirs(saving_folder, exist_ok=True)\n",
    "os.makedirs(saving_folder / 'model', exist_ok=True)\n",
    "saving_folder = str(saving_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a cpl-mixVAE object and launch its training on the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Computional node is not assigned, using CPU!\n"
     ]
    }
   ],
   "source": [
    "cplMixVAE = cpl_mixVAE(saving_folder=saving_folder)\n",
    "cplMixVAE.init_model(n_categories=n_categories,\n",
    "                     state_dim=state_dim,\n",
    "                     input_dim=data['log1p'].shape[1],\n",
    "                     lowD_dim=latent_dim,\n",
    "                     lr=lr,\n",
    "                     n_arm=n_arm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "====> Epoch:0, Total Loss: 137667456.0000, Rec_arm_1: 8.7999, Rec_arm_2: 8.7966, Joint Loss: 137578912.0000, Entropy: -7.1332, Distance: 0.4805, Elapsed Time:4.13\n",
      "====> Validation Total Loss: 28064712704.0000, Rec. Loss: 8.7721\n",
      "====> Epoch:1, Total Loss: 69825152.0000, Rec_arm_1: 8.7497, Rec_arm_2: 8.7451, Joint Loss: 69737120.0000, Entropy: -7.3747, Distance: 0.4512, Elapsed Time:3.64\n",
      "====> Validation Total Loss: 25941938176.0000, Rec. Loss: 8.6993\n",
      "====> Epoch:2, Total Loss: 42043478.0000, Rec_arm_1: 8.6571, Rec_arm_2: 8.6533, Joint Loss: 41956372.0000, Entropy: -7.3914, Distance: 0.4467, Elapsed Time:3.58\n",
      "====> Validation Total Loss: 22861494272.0000, Rec. Loss: 8.5640\n",
      "====> Epoch:3, Total Loss: 26674182.0000, Rec_arm_1: 8.4823, Rec_arm_2: 8.4839, Joint Loss: 26588808.0000, Entropy: -7.5388, Distance: 0.4278, Elapsed Time:3.60\n",
      "====> Validation Total Loss: 20230934528.0000, Rec. Loss: 8.3146\n",
      "====> Epoch:4, Total Loss: 17169558.2500, Rec_arm_1: 8.1604, Rec_arm_2: 8.1765, Joint Loss: 17087350.0000, Entropy: -7.6280, Distance: 0.4243, Elapsed Time:3.65\n",
      "====> Validation Total Loss: 20135974912.0000, Rec. Loss: 7.8776\n",
      "====> Epoch:5, Total Loss: 11332364.7500, Rec_arm_1: 7.5881, Rec_arm_2: 7.6376, Joint Loss: 11255748.0000, Entropy: -7.7191, Distance: 0.4143, Elapsed Time:3.53\n",
      "====> Validation Total Loss: 23999512576.0000, Rec. Loss: 7.1436\n",
      "====> Epoch:6, Total Loss: 8132679.8750, Rec_arm_1: 6.6561, Rec_arm_2: 6.7642, Joint Loss: 8065148.5000, Entropy: -7.7605, Distance: 0.4065, Elapsed Time:3.60\n",
      "====> Validation Total Loss: 31686617088.0000, Rec. Loss: 6.0345\n",
      "====> Epoch:7, Total Loss: 6335305.1250, Rec_arm_1: 5.3905, Rec_arm_2: 5.5418, Joint Loss: 6280293.0000, Entropy: -7.8043, Distance: 0.4005, Elapsed Time:3.63\n",
      "====> Validation Total Loss: 36792733696.0000, Rec. Loss: 4.7336\n",
      "====> Epoch:8, Total Loss: 5184599.3750, Rec_arm_1: 4.3659, Rec_arm_2: 4.3467, Joint Loss: 5140757.0000, Entropy: -7.8469, Distance: 0.3987, Elapsed Time:3.51\n",
      "====> Validation Total Loss: 38023708672.0000, Rec. Loss: 4.0776\n",
      "====> Epoch:9, Total Loss: 4790232.1250, Rec_arm_1: 4.2830, Rec_arm_2: 4.0376, Joint Loss: 4748362.0000, Entropy: -7.8604, Distance: 0.3998, Elapsed Time:3.57\n",
      "====> Validation Total Loss: 36604887040.0000, Rec. Loss: 3.9312\n",
      "Training with pruning...\n",
      "Purned categories: [1]\n",
      "====> Epoch:0, Total Loss: 4001048.3125, Rec_arm_1: 3.8611, Rec_arm_2: 3.8509, Joint Loss: 3962241.0000, Entropy: -7.8664, Distance: 0.3989, Elapsed Time:3.85\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.5026\n",
      "====> Epoch:1, Total Loss: 3639977.4375, Rec_arm_1: 3.5320, Rec_arm_2: 3.3895, Joint Loss: 3605148.2500, Entropy: -7.8894, Distance: 0.3974, Elapsed Time:3.83\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.4378\n",
      "====> Epoch:2, Total Loss: 3534881.8125, Rec_arm_1: 3.4955, Rec_arm_2: 3.3030, Joint Loss: 3500671.7500, Entropy: -7.9030, Distance: 0.3960, Elapsed Time:4.10\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.4195\n",
      "====> Epoch:3, Total Loss: 3155906.8125, Rec_arm_1: 3.4152, Rec_arm_2: 3.2708, Joint Loss: 3122262.7500, Entropy: -7.9187, Distance: 0.3939, Elapsed Time:4.40\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.3164\n",
      "====> Epoch:4, Total Loss: 2953709.7500, Rec_arm_1: 3.3518, Rec_arm_2: 3.1916, Joint Loss: 2920782.5000, Entropy: -7.9333, Distance: 0.3947, Elapsed Time:3.98\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.2596\n",
      "Training with pruning...\n",
      "Purned categories: [1 2]\n",
      "====> Epoch:0, Total Loss: 2872254.8750, Rec_arm_1: 3.3458, Rec_arm_2: 3.1647, Joint Loss: 2839493.0000, Entropy: -7.9148, Distance: 0.3927, Elapsed Time:3.81\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.2327\n",
      "====> Epoch:1, Total Loss: 2638138.1875, Rec_arm_1: 3.3082, Rec_arm_2: 3.1392, Joint Loss: 2605694.2500, Entropy: -7.9227, Distance: 0.3921, Elapsed Time:3.87\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.1979\n",
      "====> Epoch:2, Total Loss: 2455072.6250, Rec_arm_1: 3.2809, Rec_arm_2: 3.0947, Joint Loss: 2422990.5000, Entropy: -7.9277, Distance: 0.3917, Elapsed Time:3.78\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.1861\n",
      "====> Epoch:3, Total Loss: 2434174.7500, Rec_arm_1: 3.2733, Rec_arm_2: 3.0776, Joint Loss: 2402216.5000, Entropy: -7.9398, Distance: 0.3898, Elapsed Time:3.97\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.1811\n",
      "====> Epoch:4, Total Loss: 2520542.7500, Rec_arm_1: 3.2612, Rec_arm_2: 3.0682, Joint Loss: 2488693.0000, Entropy: -7.9395, Distance: 0.3899, Elapsed Time:3.85\n",
      "====> Validation Total Loss: nan, Rec. Loss: 3.1711\n",
      "No more pruning!\n",
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "model_file = cplMixVAE.train(train_loader=trainloader,\n",
    "                             test_loader=testloader,\n",
    "                             n_epoch=n_epoch,\n",
    "                             n_epoch_p=n_epoch_p,\n",
    "                             min_con=min_con,\n",
    "                             max_prun_it=max_prun_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working directly with command line, you have the option to train the model using a Python file, such as ```tutorial/train_unimodal.py``` as follows.\n",
    "\n",
    "```\n",
    "python train_unimodal.py --n_epoch 10 --n_epoch_p 5 --max_prun_it 2\n",
    "```\n",
    "or\n",
    "```\n",
    "python train_unimodal.py --n_epoch 10 --n_epoch_p 5 --max_prun_it 2 --device 'cuda'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
